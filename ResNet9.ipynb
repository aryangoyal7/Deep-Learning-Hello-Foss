{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tyH9qt7BtmR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#this is a test \n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxaW7cAjB1AL"
   },
   "outputs": [],
   "source": [
    "!pip install opendatasets --upgrade --quiet\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKrcmU1GB30o"
   },
   "outputs": [],
   "source": [
    "dataset_url = 'https://www.kaggle.com/datasets/aneesh10/cricket-shot-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6Av9jhhB4t6",
    "outputId": "0e0f1672-cfeb-4f82-9afc-ed03023a7d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./cricket-shot-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PStJ-ZdB4yI"
   },
   "outputs": [],
   "source": [
    "data_dir = './cricket-shot-dataset/data'\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXq8VFtgB41L",
    "outputId": "8e229072-a9b5-4a25-b82f-db2f6d1cc619"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive', 'pullshot', 'sweep', 'legglance-flick']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zb5W-t8xCX9t"
   },
   "outputs": [],
   "source": [
    "dataset = ImageFolder(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFZDlliwCyiQ"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as tt\n",
    "# normalize = tt.Normalize(\n",
    "#         mean=[0.4914, 0.4822, 0.4465],\n",
    "#         std=[0.2023, 0.1994, 0.2010],\n",
    "# )\n",
    "\n",
    "dataset = ImageFolder(data_dir, tt.Compose([tt.Resize(64), \n",
    "                                            tt.RandomCrop(64), \n",
    "                                            tt.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73prC60eCyta",
    "outputId": "5e14d71f-1c23-4ae8-80e7-b7525bc08621"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2362, 2362)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pct = 0.5\n",
    "val_size = int(val_pct * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCt4e48LDARQ",
    "outputId": "ab57a0ed-43ad-4bef-b1cb-d4e81d09c9d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2362, 2362)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, valid_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFLyZc1C5Yz1"
   },
   "outputs": [],
   "source": [
    "mean = 0.0\n",
    "for images, _ in train_ds: #image dim: 128*3*64*64\n",
    "    # batch_samples = images.size(0) # get batch size\n",
    "    images = images.view(images.size(0), -1) # reshape to 128*3*4096\n",
    "    mean += images.mean(1) # mean by collapsing dimension 2 then sum over dimension 1\n",
    "mean = mean / len(train_ds) # divide by total dataset as we only divided by 4096 and not 128 also\n",
    "\n",
    "var = 0.0\n",
    "for images, _ in train_ds:\n",
    "    # batch_samples = images.size(0)\n",
    "    images = images.view(images.size(0), -1)\n",
    "    var += ((images - mean.unsqueeze(1))**2).mean(1)\n",
    "std = torch.sqrt(var / (len(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNun6t8i6hRD",
    "outputId": "063b5816-d184-4ccd-ad0b-2ad343926f75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4965, 0.5012, 0.4537])\n",
      "tensor([0.2711, 0.2659, 0.2671])\n"
     ]
    }
   ],
   "source": [
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGIJwlkXFrUL"
   },
   "outputs": [],
   "source": [
    "train_ds.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean,std=std)\n",
    "            ])\n",
    "valid_ds.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean,std=std)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-7J1v44DFup",
    "outputId": "73b62da4-0268-4257-ca97-10485c89c1a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dl = DataLoader(train_ds, \n",
    "                      batch_size, \n",
    "                      shuffle=True, \n",
    "                      num_workers=4, \n",
    "                      pin_memory=True)\n",
    "\n",
    "valid_dl = DataLoader(valid_ds, \n",
    "                    batch_size, \n",
    "                    num_workers=4, \n",
    "                    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvEI5m6UDIfu"
   },
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        # Input: 128 x 3 x 64 x 64\n",
    "        self.conv1 = conv_block(in_channels, 64) # 128 x 64 x 64 x 64\n",
    "        self.conv2 = conv_block(64, 128, pool=True) # 128 x 128 x 32 x 32\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), # 128 x 128 x 32 x 32\n",
    "                                  conv_block(128, 128)) # 128 x 128 x 32 x 32\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True) # 128 x 256 x 16 x 16\n",
    "        self.conv4 = conv_block(256, 512, pool=True) # 128 x 512 x 8 x 8 \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), # 128 x 512 x 8 x 8 \n",
    "                                  conv_block(512, 512)) # 128 x 512 x 8 x 8 \n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1), # 128 x 512 x 1 x 1 \n",
    "                                        nn.Flatten(), # 128 x 512\n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9F7xKuj_DRBV"
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "in_channels = 3\n",
    "model = ResNet9(3,4).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=5, threshold=0.0001, eps=1e-08, verbose=True)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1TOrhUqDVYx",
    "outputId": "afcc9b5f-bc4c-4e12-edf0-587a0badfad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [19/19], Loss: 8.7101\n",
      "Accuracy of the network on the 5000 validation images: 28.45046570702794 %\n",
      "Epoch [2/100], Step [19/19], Loss: 1.9005\n",
      "Accuracy of the network on the 5000 validation images: 28.831498729889923 %\n",
      "Epoch [3/100], Step [19/19], Loss: 1.9171\n",
      "Accuracy of the network on the 5000 validation images: 28.535139712108382 %\n",
      "Epoch [4/100], Step [19/19], Loss: 1.3836\n",
      "Accuracy of the network on the 5000 validation images: 27.98475867908552 %\n",
      "Epoch [5/100], Step [19/19], Loss: 2.4458\n",
      "Accuracy of the network on the 5000 validation images: 31.456392887383572 %\n",
      "Epoch [6/100], Step [19/19], Loss: 1.1886\n",
      "Accuracy of the network on the 5000 validation images: 30.48264182895851 %\n",
      "Epoch [7/100], Step [19/19], Loss: 2.0653\n",
      "Accuracy of the network on the 5000 validation images: 35.732430143945805 %\n",
      "Epoch [8/100], Step [19/19], Loss: 2.1363\n",
      "Accuracy of the network on the 5000 validation images: 34.843353090601184 %\n",
      "Epoch [9/100], Step [19/19], Loss: 1.2009\n",
      "Accuracy of the network on the 5000 validation images: 37.764606265876374 %\n",
      "Epoch [10/100], Step [19/19], Loss: 2.1493\n",
      "Accuracy of the network on the 5000 validation images: 42.84504657070279 %\n",
      "Epoch [11/100], Step [19/19], Loss: 1.6267\n",
      "Accuracy of the network on the 5000 validation images: 35.266723116003384 %\n",
      "Epoch [12/100], Step [19/19], Loss: 1.1323\n",
      "Accuracy of the network on the 5000 validation images: 47.50211685012701 %\n",
      "Epoch [13/100], Step [19/19], Loss: 1.2958\n",
      "Accuracy of the network on the 5000 validation images: 47.67146486028789 %\n",
      "Epoch [14/100], Step [19/19], Loss: 1.2559\n",
      "Accuracy of the network on the 5000 validation images: 41.36325148179509 %\n",
      "Epoch [15/100], Step [19/19], Loss: 1.1260\n",
      "Accuracy of the network on the 5000 validation images: 49.3649449618967 %\n",
      "Epoch [16/100], Step [19/19], Loss: 0.9547\n",
      "Accuracy of the network on the 5000 validation images: 49.70364098221846 %\n",
      "Epoch [17/100], Step [19/19], Loss: 0.8727\n",
      "Accuracy of the network on the 5000 validation images: 56.13886536833192 %\n",
      "Epoch [18/100], Step [19/19], Loss: 0.9898\n",
      "Accuracy of the network on the 5000 validation images: 54.868755292125314 %\n",
      "Epoch [19/100], Step [19/19], Loss: 1.0398\n",
      "Accuracy of the network on the 5000 validation images: 58.46740050804403 %\n",
      "Epoch [20/100], Step [19/19], Loss: 1.3402\n",
      "Accuracy of the network on the 5000 validation images: 61.1346316680779 %\n",
      "Epoch [21/100], Step [19/19], Loss: 1.0918\n",
      "Accuracy of the network on the 5000 validation images: 61.17696867061812 %\n",
      "Epoch [22/100], Step [19/19], Loss: 0.7591\n",
      "Accuracy of the network on the 5000 validation images: 60.457239627434376 %\n",
      "Epoch [23/100], Step [19/19], Loss: 0.7749\n",
      "Accuracy of the network on the 5000 validation images: 67.31583403895004 %\n",
      "Epoch [24/100], Step [19/19], Loss: 1.1633\n",
      "Accuracy of the network on the 5000 validation images: 66.46909398814564 %\n",
      "Epoch [25/100], Step [19/19], Loss: 1.5514\n",
      "Accuracy of the network on the 5000 validation images: 68.88230313293819 %\n",
      "Epoch [26/100], Step [19/19], Loss: 0.8526\n",
      "Accuracy of the network on the 5000 validation images: 67.82387806943268 %\n",
      "Epoch [27/100], Step [19/19], Loss: 0.8905\n",
      "Accuracy of the network on the 5000 validation images: 71.54953429297206 %\n",
      "Epoch [28/100], Step [19/19], Loss: 0.5600\n",
      "Accuracy of the network on the 5000 validation images: 73.24301439458087 %\n",
      "Epoch [29/100], Step [19/19], Loss: 0.5743\n",
      "Accuracy of the network on the 5000 validation images: 74.21676545300593 %\n",
      "Epoch [30/100], Step [19/19], Loss: 0.7931\n",
      "Accuracy of the network on the 5000 validation images: 74.42845046570703 %\n",
      "Epoch [31/100], Step [19/19], Loss: 0.6039\n",
      "Accuracy of the network on the 5000 validation images: 75.4022015241321 %\n",
      "Epoch [32/100], Step [19/19], Loss: 0.7114\n",
      "Accuracy of the network on the 5000 validation images: 75.74089754445386 %\n",
      "Epoch [33/100], Step [19/19], Loss: 1.1145\n",
      "Accuracy of the network on the 5000 validation images: 74.97883149872989 %\n",
      "Epoch [34/100], Step [19/19], Loss: 0.3617\n",
      "Accuracy of the network on the 5000 validation images: 77.26502963590178 %\n",
      "Epoch [35/100], Step [19/19], Loss: 0.4645\n",
      "Accuracy of the network on the 5000 validation images: 79.33954276037257 %\n",
      "Epoch [36/100], Step [19/19], Loss: 0.2697\n",
      "Accuracy of the network on the 5000 validation images: 78.53513971210839 %\n",
      "Epoch [37/100], Step [19/19], Loss: 0.3904\n",
      "Accuracy of the network on the 5000 validation images: 83.31922099915326 %\n",
      "Epoch [38/100], Step [19/19], Loss: 0.4561\n",
      "Accuracy of the network on the 5000 validation images: 76.71464860287891 %\n",
      "Epoch [39/100], Step [19/19], Loss: 0.2612\n",
      "Accuracy of the network on the 5000 validation images: 82.81117696867062 %\n",
      "Epoch [40/100], Step [19/19], Loss: 0.1907\n",
      "Accuracy of the network on the 5000 validation images: 82.89585097375105 %\n",
      "Epoch [41/100], Step [19/19], Loss: 0.2072\n",
      "Accuracy of the network on the 5000 validation images: 80.18628281117697 %\n",
      "Epoch [42/100], Step [19/19], Loss: 0.1575\n",
      "Accuracy of the network on the 5000 validation images: 83.6155800169348 %\n",
      "Epoch [43/100], Step [19/19], Loss: 0.1527\n",
      "Accuracy of the network on the 5000 validation images: 84.84335309060118 %\n",
      "Epoch [44/100], Step [19/19], Loss: 0.1838\n",
      "Accuracy of the network on the 5000 validation images: 85.85944115156647 %\n",
      "Epoch [45/100], Step [19/19], Loss: 0.1487\n",
      "Accuracy of the network on the 5000 validation images: 87.1718882303133 %\n",
      "Epoch [46/100], Step [19/19], Loss: 0.1178\n",
      "Accuracy of the network on the 5000 validation images: 87.34123624047417 %\n",
      "Epoch [47/100], Step [19/19], Loss: 0.1076\n",
      "Accuracy of the network on the 5000 validation images: 86.62150719729043 %\n",
      "Epoch [48/100], Step [19/19], Loss: 0.3322\n",
      "Accuracy of the network on the 5000 validation images: 86.07112616426757 %\n",
      "Epoch [49/100], Step [19/19], Loss: 0.2698\n",
      "Accuracy of the network on the 5000 validation images: 85.85944115156647 %\n",
      "Epoch [50/100], Step [19/19], Loss: 0.2046\n",
      "Accuracy of the network on the 5000 validation images: 87.08721422523286 %\n",
      "Epoch [51/100], Step [19/19], Loss: 0.1090\n",
      "Accuracy of the network on the 5000 validation images: 88.0186282811177 %\n",
      "Epoch [52/100], Step [19/19], Loss: 0.0369\n",
      "Accuracy of the network on the 5000 validation images: 88.95004233700254 %\n",
      "Epoch [53/100], Step [19/19], Loss: 0.0805\n",
      "Accuracy of the network on the 5000 validation images: 87.76460626587638 %\n",
      "Epoch [54/100], Step [19/19], Loss: 0.0853\n",
      "Accuracy of the network on the 5000 validation images: 89.2887383573243 %\n",
      "Epoch [55/100], Step [19/19], Loss: 0.0638\n",
      "Accuracy of the network on the 5000 validation images: 89.66977138018628 %\n",
      "Epoch [56/100], Step [19/19], Loss: 0.0243\n",
      "Accuracy of the network on the 5000 validation images: 88.61134631668078 %\n",
      "Epoch [57/100], Step [19/19], Loss: 0.0347\n",
      "Accuracy of the network on the 5000 validation images: 87.04487722269263 %\n",
      "Epoch [58/100], Step [19/19], Loss: 0.1085\n",
      "Accuracy of the network on the 5000 validation images: 88.78069432684165 %\n",
      "Epoch [59/100], Step [19/19], Loss: 0.1004\n",
      "Accuracy of the network on the 5000 validation images: 88.82303132938188 %\n",
      "Epoch [60/100], Step [19/19], Loss: 0.0225\n",
      "Accuracy of the network on the 5000 validation images: 88.52667231160034 %\n",
      "Epoch [61/100], Step [19/19], Loss: 0.0836\n",
      "Accuracy of the network on the 5000 validation images: 88.56900931414056 %\n",
      "Epoch 00061: reducing learning rate of group 0 to 9.0000e-03.\n",
      "Epoch [62/100], Step [19/19], Loss: 0.0649\n",
      "Accuracy of the network on the 5000 validation images: 90.51651143099069 %\n",
      "Epoch [63/100], Step [19/19], Loss: 0.0674\n",
      "Accuracy of the network on the 5000 validation images: 91.06689246401355 %\n",
      "Epoch [64/100], Step [19/19], Loss: 0.0110\n",
      "Accuracy of the network on the 5000 validation images: 91.40558848433531 %\n",
      "Epoch [65/100], Step [19/19], Loss: 0.0337\n",
      "Accuracy of the network on the 5000 validation images: 91.7866215071973 %\n",
      "Epoch [66/100], Step [19/19], Loss: 0.0146\n",
      "Accuracy of the network on the 5000 validation images: 90.55884843353091 %\n",
      "Epoch [67/100], Step [19/19], Loss: 0.0302\n",
      "Accuracy of the network on the 5000 validation images: 90.55884843353091 %\n",
      "Epoch [68/100], Step [19/19], Loss: 0.0215\n",
      "Accuracy of the network on the 5000 validation images: 91.61727349703641 %\n",
      "Epoch [69/100], Step [19/19], Loss: 0.0629\n",
      "Accuracy of the network on the 5000 validation images: 90.9822184589331 %\n",
      "Epoch [70/100], Step [19/19], Loss: 0.0163\n",
      "Accuracy of the network on the 5000 validation images: 92.33700254022015 %\n",
      "Epoch [71/100], Step [19/19], Loss: 0.0092\n",
      "Accuracy of the network on the 5000 validation images: 91.87129551227773 %\n",
      "Epoch [72/100], Step [19/19], Loss: 0.0424\n",
      "Accuracy of the network on the 5000 validation images: 91.40558848433531 %\n",
      "Epoch [73/100], Step [19/19], Loss: 0.0175\n",
      "Accuracy of the network on the 5000 validation images: 91.61727349703641 %\n",
      "Epoch [74/100], Step [19/19], Loss: 0.0122\n",
      "Accuracy of the network on the 5000 validation images: 91.8289585097375 %\n",
      "Epoch [75/100], Step [19/19], Loss: 0.0426\n",
      "Accuracy of the network on the 5000 validation images: 91.61727349703641 %\n",
      "Epoch [76/100], Step [19/19], Loss: 0.0111\n",
      "Accuracy of the network on the 5000 validation images: 91.02455546147333 %\n",
      "Epoch 00076: reducing learning rate of group 0 to 8.1000e-03.\n",
      "Epoch [77/100], Step [19/19], Loss: 0.0199\n",
      "Accuracy of the network on the 5000 validation images: 92.04064352243861 %\n",
      "Epoch [78/100], Step [19/19], Loss: 0.0100\n",
      "Accuracy of the network on the 5000 validation images: 92.04064352243861 %\n",
      "Epoch [79/100], Step [19/19], Loss: 0.0169\n",
      "Accuracy of the network on the 5000 validation images: 93.09906858594411 %\n",
      "Epoch [80/100], Step [19/19], Loss: 0.0083\n",
      "Accuracy of the network on the 5000 validation images: 93.73412362404741 %\n",
      "Epoch [81/100], Step [19/19], Loss: 0.0103\n",
      "Accuracy of the network on the 5000 validation images: 92.67569856054192 %\n",
      "Epoch [82/100], Step [19/19], Loss: 0.0191\n",
      "Accuracy of the network on the 5000 validation images: 92.20999153259949 %\n",
      "Epoch [83/100], Step [19/19], Loss: 0.0075\n",
      "Accuracy of the network on the 5000 validation images: 93.01439458086368 %\n",
      "Epoch [84/100], Step [19/19], Loss: 0.0080\n",
      "Accuracy of the network on the 5000 validation images: 93.09906858594411 %\n",
      "Epoch [85/100], Step [19/19], Loss: 0.0135\n",
      "Accuracy of the network on the 5000 validation images: 92.71803556308214 %\n",
      "Epoch [86/100], Step [19/19], Loss: 0.0019\n",
      "Accuracy of the network on the 5000 validation images: 93.05673158340389 %\n",
      "Epoch 00086: reducing learning rate of group 0 to 7.2900e-03.\n",
      "Epoch [87/100], Step [19/19], Loss: 0.0032\n",
      "Accuracy of the network on the 5000 validation images: 93.4801016088061 %\n",
      "Epoch [88/100], Step [19/19], Loss: 0.0090\n",
      "Accuracy of the network on the 5000 validation images: 92.59102455546147 %\n",
      "Epoch [89/100], Step [19/19], Loss: 0.0061\n",
      "Accuracy of the network on the 5000 validation images: 93.35309060118544 %\n",
      "Epoch [90/100], Step [19/19], Loss: 0.0027\n",
      "Accuracy of the network on the 5000 validation images: 93.73412362404741 %\n",
      "Epoch [91/100], Step [19/19], Loss: 0.0059\n",
      "Accuracy of the network on the 5000 validation images: 93.77646062658764 %\n",
      "Epoch [92/100], Step [19/19], Loss: 0.0114\n",
      "Accuracy of the network on the 5000 validation images: 93.77646062658764 %\n",
      "Epoch [93/100], Step [19/19], Loss: 0.0159\n",
      "Accuracy of the network on the 5000 validation images: 93.268416596105 %\n",
      "Epoch [94/100], Step [19/19], Loss: 0.0209\n",
      "Accuracy of the network on the 5000 validation images: 93.18374259102455 %\n",
      "Epoch [95/100], Step [19/19], Loss: 0.0029\n",
      "Accuracy of the network on the 5000 validation images: 93.18374259102455 %\n",
      "Epoch [96/100], Step [19/19], Loss: 0.0042\n",
      "Accuracy of the network on the 5000 validation images: 93.14140558848433 %\n",
      "Epoch [97/100], Step [19/19], Loss: 0.0046\n",
      "Accuracy of the network on the 5000 validation images: 93.39542760372565 %\n",
      "Epoch 00097: reducing learning rate of group 0 to 6.5610e-03.\n",
      "Epoch [98/100], Step [19/19], Loss: 0.0018\n",
      "Accuracy of the network on the 5000 validation images: 93.9034716342083 %\n",
      "Epoch [99/100], Step [19/19], Loss: 0.0048\n",
      "Accuracy of the network on the 5000 validation images: 93.69178662150719 %\n",
      "Epoch [100/100], Step [19/19], Loss: 0.0035\n",
      "Accuracy of the network on the 5000 validation images: 93.14140558848433 %\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_dl)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_dl):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_dl:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "        val_acc = 100 * correct / total\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, val_acc))\n",
    "    scheduler.step(val_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
